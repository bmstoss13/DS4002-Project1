import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score
from sklearn.utils import shuffle
from sklearn.feature_extraction.text import TfidfVectorizer

df = pd.read_csv("preprocessed_data.csv")

# Shuffle data to avoid bias
df = shuffle(df, random_state=42).reset_index(drop=True)

# Extract labels and features
X = df["Preprocessed Text"]  # Preprocessed text data
y = df["Spam or Not Spam"]  # Target labels

# Split into training (80%) and testing (20%) sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Convert text to numerical representation using TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)  # Can fine-tune max_features
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Hyperparameter ranges
knn_k_values = [3, 5, 10, 15]  # Different k values for KNN
decision_tree_depths = [5, 10, 15, 20]  # Different depths for Decision Tree
cross_validation_levels = [5, 10, 15]  # Different levels of cross-validation

# Initialize models with tuning capability
models = {"Logistic Regression": LogisticRegression(max_iter=1000)}

# Add different KNN models
for k in knn_k_values:
    models[f"KNN (k={k})"] = KNeighborsClassifier(n_neighbors=k)

# Add different Decision Tree models
for depth in decision_tree_depths:
    models[f"Decision Tree (depth={depth})"] = DecisionTreeClassifier(max_depth=depth)

# Train, evaluate, and perform cross-validation
results = []
for name, model in models.items():
    model.fit(X_train_tfidf, y_train)
    
    for cv in cross_validation_levels:
        cv_scores = cross_val_score(model, X_train_tfidf, y_train, cv=cv, scoring='accuracy')
        
        # Evaluate on test set
        y_pred = model.predict(X_test_tfidf)
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, pos_label="Spam")
        
        results.append({
            "Model": name,
            "Cross-Validation Folds": cv,
            "Test Accuracy": accuracy,
            "Precision": precision,
            "Cross-Validation Accuracy": np.mean(cv_scores)
        })

# Convert results to DataFrame and save as CSV
results_df = pd.DataFrame(results)
results_df.to_csv("model_results.csv", index=False)

# Display results
for result in results:
    print(f"{result['Model']} (CV={result['Cross-Validation Folds']}):")
    print(f"  Test Accuracy: {result['Test Accuracy']:.4f}")
    print(f"  Precision: {result['Precision']:.4f}")
    print(f"  Cross-Validation Accuracy: {result['Cross-Validation Accuracy']:.4f}")
    print("-" * 40)

# Identify the best performing model
best_model = max(results, key=lambda r: r["Test Accuracy"])
if best_model["Test Accuracy"] >= 0.95:
    print(f"{best_model['Model']} (CV={best_model['Cross-Validation Folds']}) meets/exceeds 95% accuracy.")
else:
    print(f"No model reached 95% accuracy. Further tuning is needed.")
